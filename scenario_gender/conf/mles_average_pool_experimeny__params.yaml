defaults:
  - _self_
  - dataset_unsupervised/parquet
  - inference/default
  - inference/seq_encoder/pretrained

seed_everything: 42
logger_name: coles_avg_pool_model
model_path: models/coles_avg_pool_model.p
embed_file_name: coles_avg_pool_embeddings

data_module:
  _target_: ptls.frames.PtlsDataModule
  train_data:
    _target_: ptls.frames.coles.ColesDataset
    splitter:
      _target_: ptls.frames.coles.split_strategy.SampleSlices
      split_count: 5
      cnt_min: 15
      cnt_max: 75
    data: ${dataset_unsupervised.train}
  valid_data:
    _target_: ptls.frames.coles.ColesDataset
    splitter:
      _target_: ptls.frames.coles.split_strategy.SampleSlices
      split_count: 5
      cnt_min: 25
      cnt_max: 100
    data: ${dataset_unsupervised.valid}
  train_batch_size: 128
  train_num_workers: 8
  valid_batch_size: 1024
  valid_num_workers: 16

trainer: 
  accelerator: gpu
  max_epochs: 150
  enable_checkpointing: false
  deterministic: true

pl_module:
  _target_: ptls.frames.coles.CoLESModule
  validation_metric:
    _target_: ptls.frames.coles.metric.BatchRecallTopK
    K: 4
    metric: cosine
  seq_encoder:
    _target_: ptls_extension_2024_research.AvgPoolLinearSeqEncoder
    trx_encoder:
      _target_: ptls.nn.TrxEncoder
      norm_embeddings: false
      embeddings_noise: 0.003
      embeddings:
        mcc_code:
          in: 200
          out: 48
        tr_type:
          in: 100
          out: 24
      numeric_values: 
        amount: identity
  head:
    _target_: ptls.nn.Head
    use_norm_encoder: true
    # input_size: ${pl_module.seq_encoder.hidden_size}
  loss:
    _target_: ptls.frames.coles.losses.ContrastiveLoss
    margin: 0.5
    sampling_strategy:
      _target_: ptls.frames.coles.sampling_strategies.HardNegativePairSelector
      neg_count: 5
  optimizer_partial:
    _partial_: true
    _target_: torch.optim.Adam
    lr: 0.002
    weight_decay: 0.0
  lr_scheduler_partial:
    _partial_: true
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 10
    gamma: 0.9025