* Решать задачи как отедльные

---

Не обработаны: ['url_host', 'request_cnt' ]


---

1. Подготовка датасета
    1. Добавить `request_cnt`
        * Число запросов одного пользователя за время дня (поле part_of_day)
        * Как принято обрабатывать авторами: в ptls.preprocessing из коробки есть два варианта: log_norm и identity_tranasform
        * request_cnt - это числа от 1 до 16 
        * Как нормализовали в google 2015? 
    2. Добаить `url_host`
    3. Добавить 2 таргета
2. Обучение 

---
url_host - понять как выделять фичи
* разделить регуляркой по точке, по дефису и о цифрами

Можно сделать отдельную мапу домен -> эмбеддинг
Можно счиать их прямо в make_datasets_spark

1. выбросить домен верхнего уровня (ru / com)
1. Расставить пробелы, убрать ненужные символы. Предлагаю просто [a-zA-Z]+ то есть оставляем непрерываные последовательности букв
2. => bert
3. Транслитерировать => rubert
    * voronezhskaya -> воронежская
    * chto--proishodit-ru.turbopages.org что--проишодит-ру.турбопагес.орг
4. Можно банально усреднить эмбеддинги по времени; можно обучить колес
5. Можно сразу сделать pca / t-sne, чтобы посмотреть что получилось. Желательно какую-то нтервактивую верссию, чтобы виделть точки в пространсстве и при навежении было видно исхожный домен
6. xn--22-glcqfm3bya1b.xn--p1ai - так отображаются сайты, которые исходно на русском. Это, к слову, был грузчик22.рф. Нужно научиться их преобразовывать к русскому языку

---


* Мы не умеем различать порядок множества кликов с одинаковым date и part_of_day. Однако, порядок может влиять на результат.
    * Либо рандомизировать на каждой эпохе обучения
    * Либо назначить строгий порядок при создании датасета


Кажется, что для нас все события, происходящие в одно время дня как бы одновременны: например, если пользователь несколько раз зашел на один сайт за один part_of_day, мы просто указываем число таких запросов в колонке `request_cnt`

